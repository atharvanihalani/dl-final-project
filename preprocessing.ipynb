{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goal\n",
    "preprocess wav,midi into ingestible format, line up onsets\n",
    "\n",
    "mp3 -> wav -> stft/cqt -> matrix[num_onsets][frame_size/sequence length][freq_bins]\n",
    "\n",
    "midi -> piano_roll matrix[num_onsets][note_range] -> [Pitches vs Timestep] 2d-matrix\n",
    "\n",
    "num_onsets = batch size?\n",
    "sequence length depends on the sampling rate (most sr 16000)\n",
    "bin size is frequency resolution\n",
    "\n",
    "timestep/len_feats = 200, notes = 88 (piano)\n",
    "\n",
    "timestep = 1/fs\n",
    "\n",
    "input of the model: Input(shape=(len_feats, nb_notes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "#import streamlit as st\n",
    "import h5py\n",
    "\n",
    "import collections\n",
    "import datetime\n",
    "# import fluidsynth\n",
    "import glob\n",
    "import numpy as np\n",
    "import pathlib\n",
    "import pandas as pd\n",
    "import pretty_midi\n",
    "import seaborn as sns\n",
    "#import tensorflow as tf\n",
    "\n",
    "from IPython import display\n",
    "from matplotlib import pyplot as plt\n",
    "from typing import Optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "#tf.random.set_seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "# Sampling rate for audio playback\n",
    "CONTEXT_WINDOW_ROWS = 88\n",
    "HOP_LENGTH = 512\n",
    "SAMPLING_RATE = 22050\n",
    "# the num of samples per sec of 1 frame in the spectrogram\n",
    "SECONDS = 5 #duration of clips \n",
    "BINS_PER_OCTAVE = 36"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of mid files: 2\n",
      "Number of wav files: 2\n",
      "data\\wav\\bach1.wav\n",
      "data\\midi\\bach1.mid\n"
     ]
    }
   ],
   "source": [
    "# data_dir = pathlib.Path('data/SMD_raw')\n",
    "mid_data_dir = 'data/midi'\n",
    "wav_data_dir = 'data/wav'\n",
    "mid_filenames = glob.glob(str(mid_data_dir + '**/*.mid*'))\n",
    "wav_filenames = glob.glob(str(wav_data_dir + '**/*.wav*')) #tk\n",
    "\n",
    "print('Number of mid files:', len(mid_filenames))\n",
    "print('Number of wav files:', len(wav_filenames))\n",
    "\n",
    "# example use\n",
    "wav_sample_file = wav_filenames[0]\n",
    "print(wav_sample_file)\n",
    "\n",
    "mid_sample_file = mid_filenames[0]\n",
    "mid_sample_file2 = mid_filenames[1]\n",
    "\n",
    "print(mid_sample_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# wav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lame_process(input_file, output_file):\n",
    "    '''\n",
    "    Converts a single MP# file to WAV format using LAME decoder\n",
    "    param input_file: path to an input MP3 file\n",
    "    param output_file: path to save the output WAV file\n",
    "    '''\n",
    "    os.system(f'lame --decode --quiet \"{input_file}\" \"{output_file}\"')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_mp3_to_wav(input_path, output_path):\n",
    "    \"\"\"\n",
    "    Convert all MP3 files in a directory or a single MP3 file to WAV format\n",
    "    param input_path: Path to the directory containing MP3 files\n",
    "    param output_path: Path to save the converted WAV files to\n",
    "    \"\"\"\n",
    "    if os.path.isdir(input_path):\n",
    "        input_files = [file for file in os.listdir(input_path) if file.lower().endswith('.mp3')]\n",
    "        for file_name in input_files:\n",
    "            print(f'Processing {input_path}/{file_name}')\n",
    "            output_file = os.path.splitext(file_name)[0] + '.wav'\n",
    "            lame_process(os.path.join(input_path, file_name), os.path.join(output_path, output_file))\n",
    "    else:\n",
    "        lame_process(input_path, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Can't init infile '../data/SMD_raw'\n"
     ]
    }
   ],
   "source": [
    "convert_mp3_to_wav('../data/SMD_raw', \"../data/wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def wav_to_spectrogram(wav_file):\n",
    "    \"\"\"\n",
    "    Converts a wav file into a tensor input for transformer model, breaks uptensor input into 5 second segments\n",
    "    param wav: path to a wav file \n",
    "    \"\"\"\n",
    "    y, sr = librosa.load(wav_file)\n",
    "    spectrogram = librosa.cqt(y, sr = SAMPLING_RATE, bins_per_octave = BINS_PER_OCTAVE) \n",
    "    \n",
    "    #print(spectrogram.shape) #(num_freq_bins, num_time_frames)\n",
    "    spectrogram = spectrogram.T #(num_time_frames,num_freq_bins)\n",
    "    spectrogram = librosa.amplitude_to_db(np.abs(spectrogram), ref = np.max) #convert to dB scale \n",
    "    minDB = np.min(spectrogram)\n",
    "    \n",
    "    #print(f'Minimum: {np.min(spectrogram)}, Maximum: {np.max(spectrogram)}, Mean: {np.mean(spectrogram)}') \n",
    "    window_size = librosa.time_to_frames(SECONDS, sr = sr)\n",
    "    windows = [] #5 seconds worth of frames\n",
    "\n",
    "    pad_width = ((0, window_size - (spectrogram.shape[0] % window_size)), (0,0))\n",
    "    spectrogram = np.pad(spectrogram, pad_width, 'constant', constant_values = minDB) #pad spectrogram to split into 5 second frames\n",
    "    #print(f'Padded spectrogram shape: {spectrogram.shape}')\n",
    "\n",
    "    for i in range(0, spectrogram.shape[0], window_size):\n",
    "        w = spectrogram[i:i + window_size, :]\n",
    "        windows.append(w)\n",
    "    \n",
    "    windows = np.array(windows) \n",
    "    print(f'spectrogram final shape: {windows.shape}')\n",
    "\n",
    "    return windows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_spectrogram(spectrogram, sr):\n",
    "    \"\"\"\n",
    "    Creates a visualization of a spectrogram, for testing purpose\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    librosa.display.specshow(spectrogram, sr=sr, x_axis='time', y_axis='mel')\n",
    "    plt.colorbar(format='%+2.0f dB')\n",
    "    plt.title('CQT Spectrogram')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# mid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def midi_to_piano_roll(midi_file_path, start_pitch=19, end_pitch=107, sr= SAMPLING_RATE):\n",
    "    '''\n",
    "    Returns an np array of the piano roll representation of a midi file, \n",
    "    with 88 notes representing those of a piano keyboard rather than \n",
    "    the default 128 notes, that is, from MIDI note 21 (A0) to MIDI note 108 (C8).\n",
    "    '''\n",
    "    midi_data = pretty_midi.PrettyMIDI(midi_file_path)\n",
    "\n",
    "    raw_piano_roll = midi_data.get_piano_roll(fs=sr)[start_pitch:end_pitch]\n",
    "    # 0 meaning not played -> converting it into binary representation\n",
    "    piano_roll = raw_piano_roll > 0\n",
    "    piano_roll = np.asarray(piano_roll).astype(int).T\n",
    "    print(f'shape of unpadded pianoroll: {piano_roll.shape}')\n",
    "    print(f'size of unpadded pianoroll in GB: {piano_roll.itemsize * piano_roll.size}')\n",
    "\n",
    "\n",
    "    remainder = SECONDS*SAMPLING_RATE - (piano_roll.shape[0] % (SECONDS*SAMPLING_RATE))\n",
    "    pad_width = ((0, remainder), (0,0))\n",
    "    piano_roll = np.pad(piano_roll, pad_width, 'constant', constant_values=0)\n",
    "    piano_roll = np.reshape(piano_roll, (-1, SECONDS * SAMPLING_RATE, piano_roll.shape[1]))\n",
    "    print(f'shape of pianoroll after splitting: {piano_roll.shape}')\n",
    "    print(f'size of padded/split pianoroll in GB: {piano_roll.itemsize * piano_roll.size }')\n",
    "\n",
    "\n",
    "    return piano_roll\n",
    "                    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_piano_roll(midi_file_path, name_fig, start_pitch=19, end_pitch=107, sr=SAMPLING_RATE):\n",
    "    \"\"\"\n",
    "    Use librosa's specshow function for displaying the piano roll (in streamlit framework)\n",
    "    \"\"\"\n",
    "\n",
    "    fig = plt.figure(figsize=(10,8))\n",
    "    midi_data = midi_data = pretty_midi.PrettyMIDI(midi_file_path)\n",
    "\n",
    "    raw_piano_roll = midi_data.get_piano_roll(fs=sr)[start_pitch:end_pitch]\n",
    "\n",
    "    librosa.display.specshow(raw_piano_roll,\n",
    "                             hop_length=1, x_axis='time', y_axis='cqt_note',\n",
    "                             fmin=pretty_midi.note_number_to_hz(start_pitch))\n",
    "    plt.title(f\"{name_fig}\", fontsize=\"x-large\")\n",
    "    plt.xlabel(\"Time (s)\", fontsize=\"x-large\")\n",
    "    plt.ylabel(\"Pitch\", fontsize=\"x-large\")\n",
    "    st.pyplot(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of pianoroll: (3451605, 88)\n",
      "shape of pianoroll after splitting: (32, 110250, 88)\n",
      "shape of pianoroll: (5198563, 88)\n",
      "shape of pianoroll after splitting: (48, 110250, 88)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]]])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example usage\n",
    "midi_file_path1 = \"data/midi/bach1.mid\"\n",
    "midi_file_path2 = \"data/midi/bach2.mid\"\n",
    "\n",
    "\n",
    "#midi_file_path1 = mid_sample_file\n",
    "#midi_file_path2 = mid_sample_file2\n",
    "\n",
    "midi_to_piano_roll(midi_file_path1)\n",
    "midi_to_piano_roll(midi_file_path2)\n",
    "\n",
    "\n",
    "#plot_piano_roll(midi_file_path1, \"Piano Roll 1\")\n",
    "#plot_piano_roll(midi_file_path2, \"Piano Roll 2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cqt_and_pianoroll(wav_path, midi_dir, output_dir):\n",
    "    '''\n",
    "    Converts a .wav file into CQT representation and grab the\n",
    "    corresponding .midi file'''\n",
    "\n",
    "    file_name = os.path.basename(wav_path).replace('.wav', '')\n",
    "    # print(file_name)\n",
    "    mid_path = os.path.join(midi_dir, file_name + '.mid')\n",
    "    \n",
    "    if not os.path.exists(mid_path):\n",
    "        print(\"No MIDI file found:\" + mid_path)\n",
    "        return\n",
    "    \n",
    "    # print(\"Found CQT and pianorolls for \" + file_name)\n",
    "    \n",
    "    cqt = wav_to_spectrogram(wav_path) \n",
    "    piano_roll = midi_to_piano_roll(mid_path)\n",
    "\n",
    "    # print(\"converted CQT and pianorolls for \" + file_name)\n",
    "\n",
    "    h5_name = os.path.join(output_dir, file_name + \".h5\")\n",
    "    print(f'h5 name: {h5_name}')\n",
    "\n",
    "    with h5py.File(h5_name, 'a') as hf: \n",
    "        if \"pianoroll\" not in hf:\n",
    "            hf.create_dataset(\"pianoroll\", data=piano_roll)\n",
    "        if \"cqt\" not in hf:\n",
    "            hf.create_dataset(\"cqt\", data=cqt)\n",
    "\n",
    "        print(file_name + \" successfully stored in h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of wav files: 2\n",
      "spectrogram final shape: (32, 215, 84)\n",
      "shape of unpadded pianoroll: (3451605, 88)\n",
      "size of unpadded pianoroll in GB: 1214964960\n",
      "shape of pianoroll after splitting: (32, 110250, 88)\n",
      "size of padded/split pianoroll in GB: 1241856000\n",
      "h5 name: data\\pre_out\\bach1.h5\n",
      "bach1 successfully stored in h5\n",
      "spectrogram final shape: (48, 215, 84)\n",
      "shape of unpadded pianoroll: (5198563, 88)\n",
      "size of unpadded pianoroll in GB: 1829894176\n",
      "shape of pianoroll after splitting: (48, 110250, 88)\n",
      "size of padded/split pianoroll in GB: 1862784000\n",
      "h5 name: data\\pre_out\\bach2.h5\n",
      "bach2 successfully stored in h5\n"
     ]
    }
   ],
   "source": [
    "def preprocess_wav(wav_dir, midi_dir, output_dir):\n",
    "    wav_paths = glob.glob(str(wav_dir + '**/*.wav*'))  \n",
    "    print('Number of wav files:', len(wav_paths))\n",
    "\n",
    "    for wav_path in wav_paths:\n",
    "        get_cqt_and_pianoroll(wav_path, midi_dir, output_dir)\n",
    "\n",
    "preprocess_wav(\"data\\wav\", \"data\\midi\", \"data\\pre_out\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 215, 84)\n",
      "(32, 110250, 88)\n"
     ]
    }
   ],
   "source": [
    "f = h5py.File(\"data/pre_out/bach1.h5\", \"r\")\n",
    "list(f.keys())\n",
    "cqt = f['cqt']\n",
    "pianoroll = f['pianoroll']\n",
    "\n",
    "print(cqt.shape)\n",
    "print(pianoroll.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "csci1470",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
