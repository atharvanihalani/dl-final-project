{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goal\n",
    "preprocess wav,midi into ingestible format, line up onsets\n",
    "\n",
    "mp3 -> wav -> stft/cqt -> matrix[num_onsets][frame_size/sequence length][freq_bins]\n",
    "\n",
    "midi -> piano_roll matrix[num_onsets][note_range] -> [Pitches vs Timestep] 2d-matrix\n",
    "\n",
    "num_onsets = batch size?\n",
    "sequence length depends on the sampling rate (most sr 16000)\n",
    "bin size is frequency resolution\n",
    "\n",
    "timestep/len_feats = 200, notes = 88 (piano)\n",
    "\n",
    "timestep = 1/fs\n",
    "\n",
    "input of the model: Input(shape=(len_feats, nb_notes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "import streamlit as st\n",
    "import h5py\n",
    "\n",
    "import collections\n",
    "import datetime\n",
    "# import fluidsynth\n",
    "import glob\n",
    "import numpy as np\n",
    "import pathlib\n",
    "import pandas as pd\n",
    "import pretty_midi\n",
    "import seaborn as sns\n",
    "#import tensorflow as tf\n",
    "\n",
    "from IPython import display\n",
    "from matplotlib import pyplot as plt\n",
    "from typing import Optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "#tf.random.set_seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "# Sampling rate for audio playback\n",
    "CONTEXT_WINDOW_ROWS = 88\n",
    "HOP_LENGTH = 512\n",
    "SAMPLING_RATE = 22050\n",
    "# the num of samples per sec of 1 frame in the spectrogram\n",
    "SECONDS = 1 #duration of clips \n",
    "BINS_PER_OCTAVE = 36"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_dir = pathlib.Path('data/SMD_raw')\n",
    "mid_data_dir = 'data/midi'\n",
    "wav_data_dir = 'data/wav'\n",
    "mid_filenames = glob.glob(str(mid_data_dir + '**/*.mid*'))\n",
    "wav_filenames = glob.glob(str(wav_data_dir + '**/*.wav*')) #tk\n",
    "\n",
    "print('Number of mid files:', len(mid_filenames))\n",
    "print('Number of wav files:', len(wav_filenames))\n",
    "\n",
    "# example use\n",
    "wav_sample_file = wav_filenames[0]\n",
    "print(wav_sample_file)\n",
    "\n",
    "mid_sample_file = mid_filenames[0]\n",
    "mid_sample_file2 = mid_filenames[1]\n",
    "\n",
    "print(mid_sample_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# wav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lame_process(input_file, output_file):\n",
    "    '''\n",
    "    Converts a single MP# file to WAV format using LAME decoder\n",
    "    param input_file: path to an input MP3 file\n",
    "    param output_file: path to save the output WAV file\n",
    "    '''\n",
    "    os.system(f'lame --decode --quiet \"{input_file}\" \"{output_file}\"')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_mp3_to_wav(input_path, output_path):\n",
    "    \"\"\"\n",
    "    Convert all MP3 files in a directory or a single MP3 file to WAV format\n",
    "    param input_path: Path to the directory containing MP3 files\n",
    "    param output_path: Path to save the converted WAV files to\n",
    "    \"\"\"\n",
    "    if os.path.isdir(input_path):\n",
    "        input_files = [file for file in os.listdir(input_path) if file.lower().endswith('.mp3')]\n",
    "        for file_name in input_files:\n",
    "            print(f'Processing {input_path}/{file_name}')\n",
    "            output_file = os.path.splitext(file_name)[0] + '.wav'\n",
    "            lame_process(os.path.join(input_path, file_name), os.path.join(output_path, output_file))\n",
    "    else:\n",
    "        lame_process(input_path, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_mp3_to_wav('../data/SMD_raw', \"../data/wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def wav_to_spectrogram(wav_file):\n",
    "    \"\"\"\n",
    "    Converts a wav file into a tensor input for transformer model, breaks uptensor input into 5 second segments\n",
    "    param wav: path to a wav file \n",
    "    \"\"\"\n",
    "    y, sr = librosa.load(wav_file)\n",
    "    spectrogram = librosa.cqt(y, sr = SAMPLING_RATE, bins_per_octave = BINS_PER_OCTAVE) \n",
    "    \n",
    "    #print(spectrogram.shape) #(num_freq_bins, num_time_frames)\n",
    "    spectrogram = spectrogram.T #(num_time_frames,num_freq_bins)\n",
    "    spectrogram = librosa.amplitude_to_db(np.abs(spectrogram), ref = np.max) #convert to dB scale \n",
    "    minDB = np.min(spectrogram)\n",
    "    \n",
    "    #print(f'Minimum: {np.min(spectrogram)}, Maximum: {np.max(spectrogram)}, Mean: {np.mean(spectrogram)}') \n",
    "    window_size = librosa.time_to_frames(SECONDS, sr = sr)\n",
    "    windows = [] #5 seconds worth of frames\n",
    "\n",
    "    pad_width = ((0, window_size - (spectrogram.shape[0] % window_size)), (0,0))\n",
    "    spectrogram = np.pad(spectrogram, pad_width, 'constant', constant_values=minDB) #pad spectrogram to split into 5 second frames\n",
    "    #print(f'Padded spectrogram shape: {spectrogram.shape}')\n",
    "\n",
    "    for i in range(0, spectrogram.shape[0], window_size):\n",
    "        w = spectrogram[i:i + window_size, :]\n",
    "        windows.append(w)\n",
    "    \n",
    "    windows = np.array(windows) \n",
    "    print(f'Spectrogram Final Shape: {windows.shape}')\n",
    "\n",
    "    return windows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_spectrogram(spectrogram, sr):\n",
    "    \"\"\"\n",
    "    Creates a visualization of a spectrogram, for testing purpose\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    librosa.display.specshow(spectrogram, sr=sr, x_axis='time', y_axis='mel')\n",
    "    plt.colorbar(format='%+2.0f dB')\n",
    "    plt.title('CQT Spectrogram')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# mid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def midi_to_piano_roll(midi_file_path, start_pitch=19, end_pitch=107, sr= SAMPLING_RATE):\n",
    "    '''\n",
    "    Returns an np array of the piano roll representation of a midi file, \n",
    "    with 88 notes representing those of a piano keyboard rather than \n",
    "    the default 128 notes, that is, from MIDI note 21 (A0) to MIDI note 108 (C8).\n",
    "    '''\n",
    "    midi_data = pretty_midi.PrettyMIDI(midi_file_path)\n",
    "\n",
    "    raw_piano_roll = midi_data.get_piano_roll(fs=sr)[start_pitch:end_pitch]\n",
    "    # 0 meaning not played -> converting it into binary representation\n",
    "    piano_roll = raw_piano_roll > 0 # shape (pitches, Timestep) \n",
    "    piano_roll = np.asarray(piano_roll).astype(int).T #(Timestep, pitches) \n",
    "    print(f'Pianoroll Shape: {piano_roll.shape}')\n",
    "\n",
    "    remainder = SECONDS*SAMPLING_RATE - (piano_roll.shape[0] % (SECONDS*SAMPLING_RATE))\n",
    "    pad_width = ((0, remainder), (0,0))\n",
    "    piano_roll = np.pad(piano_roll, pad_width, 'constant', constant_values=0)\n",
    "    piano_roll = np.reshape(piano_roll, (-1, SECONDS * SAMPLING_RATE, piano_roll.shape[1])) \n",
    "    print(f'Pianoroll Shape After Splitting: {piano_roll.shape}') \n",
    "    # (samples, shape)\n",
    "\n",
    "    return piano_roll\n",
    "                    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_piano_roll(midi_file_path, name_fig, start_pitch=19, end_pitch=107, sr=SAMPLING_RATE):\n",
    "    \"\"\"\n",
    "    Use librosa's specshow function for displaying the piano roll (in streamlit framework)\n",
    "    \"\"\"\n",
    "\n",
    "    fig = plt.figure(figsize=(10,8))\n",
    "    midi_data = midi_data = pretty_midi.PrettyMIDI(midi_file_path)\n",
    "\n",
    "    raw_piano_roll = midi_data.get_piano_roll(fs=sr)[start_pitch:end_pitch]\n",
    "\n",
    "    librosa.display.specshow(raw_piano_roll,\n",
    "                             hop_length=1, x_axis='time', y_axis='cqt_note',\n",
    "                             fmin=pretty_midi.note_number_to_hz(start_pitch))\n",
    "    plt.title(f\"{name_fig}\", fontsize=\"x-large\")\n",
    "    plt.xlabel(\"Time (s)\", fontsize=\"x-large\")\n",
    "    plt.ylabel(\"Pitch\", fontsize=\"x-large\")\n",
    "    st.pyplot(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "# midi_file_path1 = \"data/midi/bach1.mid\"\n",
    "# midi_file_path2 = \"data/midi/bach2.mid\"\n",
    "\n",
    "midi_file_path1 = mid_sample_file\n",
    "midi_file_path2 = mid_sample_file2\n",
    "\n",
    "midi_to_piano_roll(midi_file_path1)\n",
    "midi_to_piano_roll(midi_file_path2)\n",
    "\n",
    "#plot_piano_roll(midi_file_path1, \"Piano Roll 1\")\n",
    "#plot_piano_roll(midi_file_path2, \"Piano Roll 2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cqt_and_pianoroll(wav_path, midi_dir, output_dir):\n",
    "    '''\n",
    "    Converts a .wav file into CQT representation and grab the\n",
    "    corresponding .midi file'''\n",
    "\n",
    "    file_name = os.path.basename(wav_path).replace('.wav', '')\n",
    "    # print(file_name)\n",
    "    mid_path = os.path.join(midi_dir, file_name + '.mid')\n",
    "    \n",
    "    if not os.path.exists(mid_path):\n",
    "        print(\"No MIDI file found:\" + mid_path)\n",
    "        return\n",
    "    \n",
    "    # print(\"Found CQT and pianorolls for \" + file_name)\n",
    "    \n",
    "    cqt = wav_to_spectrogram(wav_path) \n",
    "    piano_roll = midi_to_piano_roll(mid_path)\n",
    "\n",
    "    # print(\"converted CQT and pianorolls for \" + file_name)\n",
    "\n",
    "    h5_name = os.path.join(output_dir, file_name + \".h5\")\n",
    "\n",
    "    with h5py.File(h5_name, 'a') as hf: \n",
    "        if \"pianoroll\" not in hf:\n",
    "            hf.create_dataset(\"pianoroll\", data=piano_roll)\n",
    "        if \"cqt\" not in hf:\n",
    "            hf.create_dataset(\"cqt\", data=cqt)\n",
    "\n",
    "        print(file_name + \" successfully stored in h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m wav_path \u001b[38;5;129;01min\u001b[39;00m wav_paths:\n\u001b[1;32m      6\u001b[0m         get_cqt_and_pianoroll(wav_path, midi_dir, output_dir)\n\u001b[0;32m----> 8\u001b[0m \u001b[43mpreprocess_wav\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdata/wav\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdata/midi\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdata/pre_out\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[13], line 6\u001b[0m, in \u001b[0;36mpreprocess_wav\u001b[0;34m(wav_dir, midi_dir, output_dir)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNumber of wav files:\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28mlen\u001b[39m(wav_paths))\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m wav_path \u001b[38;5;129;01min\u001b[39;00m wav_paths:\n\u001b[0;32m----> 6\u001b[0m     \u001b[43mget_cqt_and_pianoroll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwav_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmidi_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[12], line 17\u001b[0m, in \u001b[0;36mget_cqt_and_pianoroll\u001b[0;34m(wav_path, midi_dir, output_dir)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# print(\"Found CQT and pianorolls for \" + file_name)\u001b[39;00m\n\u001b[1;32m     16\u001b[0m cqt \u001b[38;5;241m=\u001b[39m wav_to_spectrogram(wav_path) \n\u001b[0;32m---> 17\u001b[0m piano_roll \u001b[38;5;241m=\u001b[39m \u001b[43mmidi_to_piano_roll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmid_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# print(\"converted CQT and pianorolls for \" + file_name)\u001b[39;00m\n\u001b[1;32m     21\u001b[0m h5_name \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(output_dir, file_name \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[9], line 9\u001b[0m, in \u001b[0;36mmidi_to_piano_roll\u001b[0;34m(midi_file_path, start_pitch, end_pitch, sr)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03mReturns an np array of the piano roll representation of a midi file, \u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03mwith 88 notes representing those of a piano keyboard rather than \u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;124;03mthe default 128 notes, that is, from MIDI note 21 (A0) to MIDI note 108 (C8).\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m      7\u001b[0m midi_data \u001b[38;5;241m=\u001b[39m pretty_midi\u001b[38;5;241m.\u001b[39mPrettyMIDI(midi_file_path)\n\u001b[0;32m----> 9\u001b[0m raw_piano_roll \u001b[38;5;241m=\u001b[39m \u001b[43mmidi_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_piano_roll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msr\u001b[49m\u001b[43m)\u001b[49m[start_pitch:end_pitch]\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# 0 meaning not played -> converting it into binary representation\u001b[39;00m\n\u001b[1;32m     11\u001b[0m piano_roll \u001b[38;5;241m=\u001b[39m raw_piano_roll \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/csci1470/lib/python3.10/site-packages/pretty_midi/pretty_midi.py:823\u001b[0m, in \u001b[0;36mPrettyMIDI.get_piano_roll\u001b[0;34m(self, fs, times, pedal_threshold)\u001b[0m\n\u001b[1;32m    821\u001b[0m \u001b[38;5;66;03m# Sum each piano roll into the aggregate piano roll\u001b[39;00m\n\u001b[1;32m    822\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m roll \u001b[38;5;129;01min\u001b[39;00m piano_rolls:\n\u001b[0;32m--> 823\u001b[0m     piano_roll[:, :roll\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m roll\n\u001b[1;32m    824\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m piano_roll\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def preprocess_wav(wav_dir, midi_dir, output_dir):\n",
    "    wav_paths = glob.glob(str(wav_dir + '**/*.wav*'))  \n",
    "    print('Number of wav files:', len(wav_paths))\n",
    "\n",
    "    for wav_path in wav_paths:\n",
    "        get_cqt_and_pianoroll(wav_path, midi_dir, output_dir)\n",
    "\n",
    "preprocess_wav(\"data/wav\", \"data/midi\", \"data/pre_out\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "csci1470",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
